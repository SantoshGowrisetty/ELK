#Configure filebeat (plugin) to send log lines to logstash

The Filebeat client is a lightweight, resource-friendly tool that collects logs from files on 
the server and forwards these logs to your Logstash instance for processing.
Filebeat is designed for reliability and low latency.Filebeat has a light resource footprint
on the host machine, and the Beats input plugin minimizes the resource demands on the Logstash
instance.
#Download and install the Public Signing Key:
$sudo wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -

#Install “apt-transport-https” and add repo.
$sudo apt-get install apt-transport-https

$sudo echo "deb https://artifacts.elastic.co/packages/6.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list

#Update repo and install Filebeat
$sudo apt-get update
$sudo apt-get install filebeat

#Modify Filebeat configurations.
$sudo vim /etc/filebeat/filebeat.yml

enabled: true
paths:
    - /var/log/elasticsearch/mycluster.log

#Uncomment the following lines:
output.logstash:
  # The Logstash hosts
  hosts: ["elk-server:5443"]
  ssl.certificate_authorities: ["/etc/filebeat/logstash-forwarder.crt"]

#Comment Elasticsearch:
#output.elasticsearch:
  # Array of hosts to connect to.
  # hosts: ["localhost:9200"]

#Now go to logstash server and get “logstash-forwarder.crt” contents
$sudo cat /etc/logstash/ssl/logstash-forwarder.crt
#get the contents 

#create a certificate file on filebeat client server
$sudo vim /etc/filebeat/logstash-forwarder.crt
#copy the logstash-forwarder.crt contents here

#Enable filebeat on system boot Start filebeat service
$sudo systemctl enable filebeat.service
$sudo systemctl start filebeat.service
$sudo service filebeat status
$sudo service filebeat stop

#we will start it again after we setup logstash to accept beats..

###on logstash running node#####
#Creating a sample pipeline on logstash node to accept beats from filebeat on client server
#To Test

$root@u1:~# vi /etc/logstash/conf.d/first-pipeline.conf
input{
  beats {
        port => "5443"
        }
     }
output {
       stdout{codec => "rubydebug"}
       }

#Testing newly created config
root@u1:~# /usr/share/logstash/bin/logstash --path.settings /etc/logstash/ -f /etc/logstash/conf.d/first-pipeline.conf --config.test_and_exit

#To run logstash with above mentioned config, remember to update output location in *.conf to receive content sent by filebeat and forward it 
#as per location

input{
  beats {
        port => "5443"
        }
     }
output {
     elasticsearch {
          hosts => "192.168.56.104"
          index => "LogInfo"
          document_type => "AllLogs"
      }
      stdout {}

#now start logstash with this config
root@u1:~# /usr/share/logstash/bin/logstash --path.settings /etc/logstash/ -f /etc/logstash/conf.d/first-pipeline.conf

###on filebeat running node####
#to check
root@u2:/usr/share/filebeat/bin# ./filebeat -e -c /etc/filebeat/filebeat.yml -d "publish"

#if fine, start filebeat service
#start filebeat as a service or start filebeat from command line from /usr/share/bin/filebeat
===========================
#check from Kibana if filebeat is sending data to logstash,if logstash is fwding same to Elasticsearch 
and a new index is created.

