#paths may have changed, read through and recheck in git 
#conf files exist in MyConfigsLS

#change paths according to your setup

>>MyConfigsLS/conf.d/newpipeline.conf
>>MyConfigsLS/conf.d/newpipeline2.conf

#Using Logstash for sending TCP data to ES.
#you can initially try with one pipeline

These files are found in cluster_setup/Logstash_Work/myconfigs/conf.d
#when running logstash check if your logstash is in /etc/logstash or in /usr/local/logstash and
choose the one you prefer and have configured.

newpipeline.conf
input {
  tcp {
    port => 9000
    type => syslog
  }
}
filter {
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "received_from", "%{host}" ]
    }
    date {
      match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }
  }
}
output {
  stdout {codec => rubydebug}
  elasticsearch {
    hosts => ["ce1:9200"]
    index => "tcpdata9000-%{+YYYY.MM.dd}"
  }
}

newpipeline2.conf
input {
  tcp {
    port => 9001
    type => syslog
  }
}
filter {
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "received_from", "%{host}" ]
    }
    date {
      match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
    }
  }
}
output {
  stdout {codec => rubydebug}
  elasticsearch {
    hosts => ["ce2:9200"]
    index => "tcpdata9001-%{+YYYY.MM.dd}"
  }
}

#start pipelines
/usr/local/logstash/bin/logstash --path.settings /usr/local/logstash -f /usr/local/logstash/conf.d/newpipeline.conf --path.data /var/lib/logstash_temp/temp1
/usr/share/logstash/bin/logstash --path.settings /usr/local/logstash -f /usr/local/logstash/conf.d/newpipeline2.conf --path.data /var/lib/logstash_temp/temp2

#check if listener on designed port is active
#send some data 
curl telnet://localhost:9000

#send some data
curl telnet://localhost:9001

#check from kibana 
-if indexes were created
-create index pattern and check if index received documents

#file can be found in /myconfigs/conf.d > newpipeline.conf
