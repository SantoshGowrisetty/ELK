DocArray

---------
Like Json , but for intensive computation.
It is like numpy.narray , but for unstructured data.
It is like pandas.DataFrame, but for nested and mixed media data with embeddings.(https://pypi.org/project/embeddings/)
Embeddings is a python package that provides pretrained word embeddings for natural language processing and machine learning.

Instead of loading a large file to query for embeddings, embeddings is backed by a database and fast to load and query.

--------------------------------------------
Embeddings (for more details refer : Embeddings-Readme)

For example: GloveEmbedding
GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus, and the resulting representations showcase interesting linear substructures of the word vector space.

>>> %timeit GloveEmbedding('common_crawl_840', d_emb=300)
100 loops, best of 3: 12.7 ms per loop

>>> %timeit GloveEmbedding('common_crawl_840', d_emb=300).emb('canada')
100 loops, best of 3: 12.9 ms per loop

>>> g = GloveEmbedding('common_crawl_840', d_emb=300)

>>> %timeit -n1 g.emb('canada')
1 loop, best of 3: 38.2 µs per loop

Installation:
pip install embeddings  # from pypi
pip install git+https://github.com/vzhong/embeddings.git  # from github

Usage:
Upon first use, the embeddings are first downloaded to disk in the form of a SQLite database. This may take a long time for large embeddings such as GloVe. Further usage of the embeddings are directly queried against the database. Embedding databases are stored in the $EMBEDDINGS_ROOT directory (defaults to ~/.embeddings).

from embeddings import GloveEmbedding, FastTextEmbedding, KazumaCharEmbedding, ConcatEmbedding

g = GloveEmbedding('common_crawl_840', d_emb=300, show_progress=True)
f = FastTextEmbedding()
k = KazumaCharEmbedding()
c = ConcatEmbedding([g, f, k])
for w in ['canada', 'vancouver', 'toronto']:
    print('embedding {}'.format(w))
    print(g.emb(w))
    print(f.emb(w))
    print(k.emb(w))
    print(c.emb(w))


--------------------------------------------------------
It is like protobuf, but for data scientists and deep learning engineers.
If you are a data scientist who works with image, text, video, audio data in Python all day, you should use DocArray: it can greatly accelerate the work on representing, embedding, matching, visualizing, evaluating, sharing data; while staying close to your favorite toolkits, e.g. Torch, TensorFlow, ONNX, PaddlePaddle, JupyterLab, Google Colab.

If you are a deep learning engineer who works on scalable deep learning services, you should use DocArray: it can be the basic building block of your system. Its portable data structure can be wired in Protobuf, compressed bytes, JSON; allowing your engineer friends to happily integrate it into the production system.

This is DocArray: a unique one, aiming to be your data structure for unstructured data.
------------------------------------------------------

DocArray Design:
Document: a data structure for easily representing nested,unstructured data.
DocumentArray: a container for effeciently accessing, processing
and understanding multiple documents.
Dataclass: a high-level API for intuitively representing multimodal data.

DocArray is designed to represent multimodal data intuitively to face the ever-increasing development of multi-modal applications.

example:
from docarray import dataclass, Document
from docarray.typing import Image, Text, JSON

@dataclass
class WPArticle:
     banner: Image = 'cat-dog-flight.png'
     headline: Text = 'Everything to know about flying with pets, from
     picking your seats to keeping your animal calm'
     meta: JSON = {
        'author': 'Nathan Diller'
        'Column': 'By the way - A Post Travel Destination'}
Document(WPArticle())

----------------
Other alternatives:
-numpy.ndarray
-Json
-pandas.DataFrame
-Protobuf

3 other well known packages:
Hugging Face Datasets:

HFD 
Is a library for easily accessing and sharing datasets for NLP, computer vision, and audio tasks. One of the highlights is its efficient loading of large datasets, which is highly appreciated during training.

In DocArray, there will also be a couple of feature releases soon to allow big data loading with constant memory consumption. However, the biggest difference is that DocArray is focused on data in transit, whereas HF Datasets is about data at rest. DocArray is focused on active data that is subject to frequent change; and allows efficient transfer between threads, processes and microservices. Data in transit often traverses a network or temporarily resides in memory to be read or updated. That’s opposed to Datasets, where training data is stored physically and statically, and is subject to very occasional changes. 

Data at rest
Inactive data under very occasional changes, stored physically in database,
warehouse, spreadsheet, archives etc.

Data in use:
Active data under constant change, stored physically in database,warehouse,
spreadsheet etc.

Data in transit:
Traversing a network or temporarily residing in computer memory to be read
or updated.

To AwkwardArray:
AA
is a library for manipulating JSON/dict data via NumPy idioms. Instead of working with Python dynamically typed objects, AwkwardArray converts data into precompiled routines on contiguous data. Hence, it is highly efficient.

DocArray and AwkwardArray are designed with different purposes: DocArray comes from the context of deep learning engineering that works on a stream of multi/cross-modal Documents. AwkwardArray comes from particle physics where with high-performance number-crunching is the priority. Both shares the idea of having a generic data structure, but are designed differently to maximize the productivity in their own domains. This results in different sets of feature functions.

When it comes to speed, AwkwardArray is fast at column access whereas DocArray is fast at row access (streaming):

import awkward as ak
import numpy as np
from docarray import DocumentArray
from toytime import TimeContext

da = DocumentArray.empty(100_000)
da.embeddings = np.random.random([len(da), 64])

da.texts = [f'hello {j}' for j in range(len(da))]

ak_array = ak.from_iter(da.to_list())

with TimeContext('iter via DocArray'):
    for d in da:
        pass

with TimeContext('iter via awkward'):
    for r in ak_array:
        pass

with TimeContext('access text via DocArray'):
    da.texts

with TimeContext('access text via awkward'):
    ak_array['text']

To Zarr
Zarr is a format for the storage of chunked, compressed, N-dimensional arrays. It is the package when a numpy.ndarray is too big to fit into memory. Zarr provides a comprehensive set of functions that lets you chunk, compress, and stream a large ndarray. Hence, from that perspective, Zarr, like numpy.ndarray focuses on numerical representation and computation.

In DocArray, the basic element you work with is a Document, not ndarray. The support of ndarray is important, but not the full story: in the context of deep learning engineering, ndarray is often an intermediate representation of Document for computing, then thrown away. Therefore, having a consistent data structure that lives long enough to cover creating, storing, computing, transferring, returning and rendering is one of the major motivations of DocArray.

-----------
Jina Users
The speedup comes from the complete redesign of Document and DocumentArray.

Beside code refactoring and optimization, many features have been improved, including:

Advanced indexing for both elements and attributes

Comprehensive serialization protocols

Unified and improved Pythonic interface

Improved visualization of Document and DocumentArray

Revised documentation and examples

… and many more

When first using DocArray, some Jina 2.x users may realize the static typing seems missing. This is due to a deliberate decision of DocArray: DocArray guarantees the types and constraints of the wire data, not the input data. 

----------------------------

Document:

Basic data type in DocArray.
working with text, image, video, audio, 3D meshes or the nested or the combined of them, you can always represent them as Document.

A Document object has a predefined data schema , each of the attributes can be set/get with the dot expression as you would do with any Python object.

id
string
A hexdigest that represents a unique document ID

blob
bytes
the raw binary content of this document, which often represents the original document

tensor
ndarray-like
the ndarray of the image/audio/video document
An ndarray-like object can be a Python (nested) List/Tuple, Numpy ndarray, SciPy sparse matrix (spmatrix), TensorFlow dense and sparse tensor, PyTorch dense and sparse tensor, or PaddlePaddle dense tensor.

text
string
a text document

granularity
int
the depth of the recursive chunk structure

adjacency
int
the width of the recursive match structure

parent_id
string
the parent id from the previous granularity

weight
float
The weight of this document

uri
string
a uri of the document could be: a local file path, a remote url starts with http or https or data URI scheme

modality
string
modality, an identifier to the modality this document belongs to. In the scope of multi/cross modal search

mime_type
string
mime type of this document, for blob content, this is required; for other contents, this can be guessed

offset
float
the offset of the doc

location
float
the position of the doc, could be start and end index of a string; could be x,y (top, left) coordinate of an image crop; could be timestamp of an audio clip

chunks
DocumentArray
list of the sub-documents of this document (recursive structure)

matches
DocumentArray
the matched documents on the same level (recursive structure)

embedding
ndarray-like
the embedding of this document

tags
dict
a structured data value, consisting of field which map to dynamically typed values.

scores
NamedScore
Scores performed on the document, each element corresponds to a metric

evaluations
NamedScore
Evaluations performed on the document, each element corresponds to a metric

The Document’s data schema is comprehensive and well-organized. You can categorize its attributes into several groups:

Content related: uri, text, tensor, blob;
Nest structure related: chunks, matches, granularity, adjacency, parent_id;
Common side information or metadata: id, modality, mime_type, offset, location, weight;
Further information: tags;
Computational related: scores, evaluations, embedding.

---------------------
Working with documents:
---
docArr1.py
from docarray import Document
import numpy

#construct an empty document
d = Document()

#Each Document has a unique random id to identify it. It can be used to access the Document inside a DocumentArray.
#The random id is the hex value of UUID1. To convert it into the a UUID string

import uuid
dconv = str(uuid.UUID(d.id))

#initializing a Document object with the given attributes
d1 = Document(text='hello')
d2 = Document(blob=b'\f1')
d3 = Document(tensor=numpy.array([1, 2, 3]))
d4 = Document(
    uri='https://docarray.jina.ai',
    mime_type='text/plain',
    granularity=1,
    adjacency=3,
    tags={'foo': 'bar'},
)

#Use print that shows the Document’s non-empty attributes as well as its id
print('d is   :', d)
print(type(d))
print('dconverted is    :' ,dconv)
print('d1 is    :', d1)
print(d1.text)
print(d1.tags)
print(d1.id)
print(d1.embedding)

print('d2 is    :', d2)
print(d2.blob)

print('d3 is    :', d3)
print('d4 is    :', d4,d4.tags)

#wrap keyword arguments into a dict
d5 = Document(
    uri='https://docarray.jina.ai',
    mime_type='text/plain',
    granularity=1,
    adjacency=3
)

d6 = Document(
    dict(
        uri='https://docarray.jina.ai',
        mime_type='text/plain',
        granularity=1,
        adjacency=3,
    )
)

d7 = Document(
    {
      'uri': 'https://docarray.jina.ai',
        'mime_type': 'text/plain',
        'granularity': 1,
        'adjacency': 3,
    }
)

print('d5 is    :', d5)
print(d5.id)
print(d5.mime_type)
print(d5.is_multimodal)

print('d6 is    :', d6)
print('d7 is    :', d7)

---
---
#docArr2.py
'''
manually construct a nested Document, for example to hold different modalities, like text and image.
To construct multimodal Documents in a more comfortabe, readable, and idiomatic way you should use DocArray’s dataclass API.
'''
#Documents can be nested inside .chunks and .matches
from docarray import Document

d = Document(
    id='d0',
    chunks=[Document(id='d1', chunks=Document(id='d2'))],
    matches=[Document(id='d3')],
)

print(d)
print(d.summary())

#giving an unknown attribute
#If you give an unknown attribute (i.e. not one of the built-in Document attributes), it is automatically “caught” into the .tags attribute
d = Document(hello='world')
print(d, d.tags)

#esolve external fields into built-in attributes by specifying a mapping in field_resolver.
d = Document(hello='world', field_resolver={'hello': 'id'})
print(d)
print(d.non_empty_fields)
print(d.id)

#copy from another document
d = Document(text='hello')
d1 = Document(d, copy=True)
print(d == d1, id(d) == id(d1))
#This indicates d and d1 have identical content, but they are different objects in memory.

#keep the memory address of a Document object while only copying the content from another Document, you can use copy_from().
d1 = Document(text='hello')
d2 = Document(text='world')

print(id(d1))
d1.copy_from(d2)
print(d1.text)
print(id(d1))
-----------
#docArr3.py
#From/to JSON
#pip install "docarray[full]"
#Documents use JSON Schema and pydantic model for serialization, i.e. protocol='jsonschema'.
#When using a RESTful API, you should use protocol='jsonschema' as the resulting JSON will follow a pre-defined schema.
# To use Protobuf as the JSON serialization backend, pass protocol='protobuf' to the method
from docarray import Document
import numpy as np

d = Document(text='hello, world', embedding=np.array([1, 2, 3]))
d_as_json = d.to_json(protocol='protobuf')

print(d)
print(d,d_as_json)
print(d.embedding)
print(d.non_empty_fields)
print(d.id)
print(d.text)
print(d.content)
print(d.is_multimodal)

#From/to bytes
#Depending on your protocol and compress argument values, this feature may require protobuf and lz4 dependencies
'''Bytes or binary or buffer, however you want to call it, is probably 
the most common and compact wire format. DocArray provides to_bytes() and from_bytes() 
to serialize Document objects into bytes.'''
d = Document(text='hello, world', embedding=np.array([1, 2, 3]))
d_bytes = d.to_bytes()
d_r = Document.from_bytes(d_bytes)
print(d_bytes, "\n", d_r)
print(len(d_bytes))

#The default serialization protocol is pickle – you can change it to protobuf by specifying
# .to_bytes(protocol='protobuf'). You can also add compression to make the resulting bytes smaller
print(len(d.to_bytes(protocol='protobuf', compress='gzip')))

#with RESTful APIs, you can only send/receive strings, not bytes. You can serialize a Document
# into a base64 string with to_base64() and load it with from_base64()
d = Document(text='hello', embedding=[1, 2, 3])
print(d.to_base64())
print(len(d.to_base64()))
print(len(d.to_base64(protocol='protobuf', compress='lz4')))

#from/to dict
d_as_dict = Document(text='hello, world', embedding=np.array([1, 2, 3]))
d = d_as_dict.to_dict(protocol='protobuf')
print(type(d))
for i in d.items():
    print(i)
print(d)

#protobuf
d_proto = Document(uri='apple.jpg').to_protobuf()
print(type(d_proto), d_proto)
d = Document.from_protobuf(d_proto)
-----------
#docArr4.py
#Accessing attributes
#Use . expression to get/set the value of an attribute
import docarray
from docarray import  Document,DocumentArray
d = Document()
d.text = 'hello world'
print(d.text)
print(d.id)
print(d.non_empty_fields)
#unsetting an attribute
d.pop('text')
print(d.text)
d.text = 'hello world'
print(d.text)
d.text = None
print(d.text)

#the most important are content attributes, namely .text, .tensor, and .blob which contain the actual content.
#Each document can contain only one kind of attribute
import numpy as np
from docarray import Document

d = Document(text='hello')
print(d.text)
print(d)
d.tensor = np.array([1, 2, 3])
print(d)
print(d.tensor)
print(d.content)
print(d.non_empty_fields)

#to represent more than one kind of information i.e. text and images (such as coming from PDF), we can use
#nested documents
#Each Document contains only one modality of information.
d = Document(chunks=[Document(tensor=[1, 2, 3]), Document(text='Hello')])
print(d)
print(d.non_empty_fields)
print(d.chunks)
print(d.chunks.texts)

#using content setter and getter
d1 = Document(content='hello')
print(d1)
print(d1.content_type)
print(d1.content)

d1.content = [1,2,3]
print(d1)
print(d1.content_type)
print(d1.content)

#Load content from uri
d1 = Document(uri='/home/hdu/Downloads/apple2.png').load_uri_to_image_tensor()
print(d1.content_type, d1.content)
print(d1.non_empty_fields)

d2 = Document(uri='https://www.gutenberg.org/files/1342/1342-0.txt').load_uri_to_text()
print(d2.content_type, d2.content)
---------------------------------
#docArr5.py
#embedding
#a multi-dimensional representation of a Document (often a [1, D] vector)

import numpy as np
import scipy.sparse as sp
from docarray import Document

d0 = Document(embedding=[1, 2, 3])
d1 = Document(embedding=np.array([1, 2, 3]))
d2 = Document(embedding=np.array([[1, 2, 3], [4, 5, 6]]))
d3 = Document(embedding=sp.coo_matrix([0, 0, 0, 1, 0]))

print(d0.embedding)
print(d0.non_empty_fields)
print(d0.embedding.count(2))
print(d2.summary())
print(d3.summary())

#instead of manually specifying embedding, use a DNN with .embed option
q = (Document(uri='/home/hdu/Downloads/apple1.jpg')
     .load_uri_to_image_tensor()
     .set_image_tensor_normalization()
     .set_image_tensor_channel_axis(-1, 0))

#embed it into a vector
import torchvision
model = torchvision.models.resnet50(pretrained=True)
d = q.embed(model)

print(d.embedding)
print(d.summary())
print(d.non_empty_fields)
print(type(d))

#Documents with an .embedding can be “matched” against each other.
q1 = (Document(uri='/home/hdu/Downloads/apple1.jpg')
     .load_uri_to_image_tensor()
     .set_image_tensor_normalization()
     .set_image_tensor_channel_axis(-1, 0))

q2 = (Document(uri='/home/hdu/Downloads/apple2.png')
     .load_uri_to_image_tensor()
     .set_image_tensor_normalization()
     .set_image_tensor_channel_axis(-1, 0))

q3 = (Document(uri='/home/hdu/Downloads/apple3.png')
     .load_uri_to_image_tensor()
     .set_image_tensor_normalization()
     .set_image_tensor_channel_axis(-1, 0))

print(q1.summary())
print(q2.summary())
print(q3.summary())
import torchvision
model = torchvision.models.resnet50(pretrained=True)
d1 = q1.embed(model)
d2 = q2.embed(model)
d3 = q3.embed(model)

from docarray import DocumentArray
da = DocumentArray([d1,d2,d3])
print(da.contents)
print(da.embeddings)
d1.match(da)
d3.match(da)

#we create ten Documents and put them into a DocumentArray, and then use another Document to search against them.
da = DocumentArray.empty(10)
da.embeddings = np.random.random([10, 256])
q = Document(embedding=np.random.random([256]))
q.match(da)
q.summary()

--------------------------
#docArr6.py
#Nested Structure
#Documents can be nested both horizontally and vertically via .matches and .chunks
from docarray import Document

d = Document(chunks=[Document(text='Hello')], matches=[Document(text='Hi'), Document(text='Hey')])
print(d.non_empty_fields)
print(d)
print(d.summary())
print(d.chunks.contents)
print(d.matches.contents)

d.chunks = [Document(text='World'), Document(text='Countries')]
print(d.chunks.contents)
print(d.matches.contents)
print(d.summary())
d.chunks.append(Document(text='Hello Again'))
print(d.summary())
print(d.chunks.contents)
print(d.matches.contents)
print(d)

print(type(d))
print(type(d.chunks))
print(type(d.matches))

#Visualize documents
import numpy as np
from docarray import Document

d0 = Document(id='🐲', embedding=np.array([0, 0]))
d1 = Document(id='🐦', embedding=np.array([1, 0]))
d2 = Document(id='🐢', embedding=np.array([0, 1]))
d3 = Document(id='🐯', embedding=np.array([1, 1]))

d0.chunks.append(d1)
d0.chunks[0].chunks.append(d2)
d0.matches.append(d3)
print(d0.summary())

#Using Fluent interface
#process (often preprocess) a Document object by chaining methods.
# For example to read an image file as numpy.ndarray, resize it, normalize it and then store it to another file

from docarray import Document

d = (
    Document(uri='/home/hdu/Downloads/apple1.jpg')
    .load_uri_to_image_tensor()
    .set_image_tensor_shape((64, 64))
    .set_image_tensor_normalization()
    .save_image_tensor_to_file('/home/hdu/Downloads/apple4.png')
)

----------------
#docArr7.py
#working with DocumentArray
from docarray import Document,DocumentArray
da = DocumentArray()
da.append(Document(text='hello world!'))
da.extend([Document(text='hello'), Document(text='world!')])
da.summary()
print(da[0].content,da[1].content)
print(da[0].id,da[0].content,"\n",da[1].id,da[1].content)
print(da['be47bbdcc3d0d236f353940071900fb7'])
print(da['be47bbdcc3d0d236f353940071900fb7'].content)

newdoc = Document(text='test world!')
da.extend([newdoc])
da.summary()
newdoc in da

da.__len__()

#using boolean mask for updating or filtering certain Documents
mask = [True, False] * 2
del da[mask]
print(da)
print(da.__len__())

#Working with nested structures
#DocumentArray provides makes it easy to traverse over the nested structure and select Documents:
#A path represents the route from the top-level Documents to the destination. Use c to select chunks,
# cc to select chunks of chunks, m to select matches, mc to select chunks of matches, r to select top-level Documents.

#using .empty to add empty documents
da = DocumentArray().empty(3)
print(da.summary())

#using .empty to add empty documents in chunks and matches
for d in da:
    d.chunks = DocumentArray.empty(2)
    d.matches = DocumentArray.empty(2)

da[0] = Document(text='Test')
da[0].content

for d in da:
    d.chunks = DocumentArray.empty(2)
    d.matches = DocumentArray.empty(2)

print(da.summary())

print(da['@m'])
print(da['@m'],"\n",da['@m'][0],"\n",da['@m'][1])
print(da['@c'],"\n",da['@c'][0],"\n",da['@c'][1])

print(da['@c,m'])
print(da['@c,m,r'])
#other options can be
# da['@mc']
# da['@cm,cc']
# da['@m,cm']
#da['@m:5,c:3]']

#flat DocumentArray without all nested structure
da1 = DocumentArray().empty(3)
for d in da1:
    d.chunks = DocumentArray.empty(2)
    d.matches = DocumentArray.empty(2)

da1[...].summary()

#Batching document array using
#match()
#map_batch() -- for in parallel, to overall cpu & gpu computation
da = DocumentArray.empty(1000)
for b_da in da.batch(batch_size=256):
    print(b_da)

#using sampling
da = DocumentArray.empty(1000).sample(10)
print(da)

#shuffling
da = DocumentArray.empty(1000)
da.shuffle()

#Splitting by tags
#We can split a DocumentArray into multiple DocumentArrays according to a tag value
# (stored in tags) of each Document. It returns a Python dict where Documents with the same tag value are grouped
# together in a new DocumentArray, with their orders preserved from the original DocumentArray.

da = DocumentArray(
    [
        Document(tags={'category': 'c'}),
        Document(tags={'category': 'c'}),
        Document(tags={'category': 'b'}),
        Document(tags={'category': 'a'}),
        Document(tags={'category': 'a'}),
    ]
)

rv = da.split_by_tag(tag='category')
da.summary()

------------------




























































