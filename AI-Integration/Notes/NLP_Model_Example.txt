https://colab.research.google.com/drive/1hBwM6QITP8elGEI05L9SwAGqozgI1vRT?usp=sharing#scrollTo=fCell_jKXTds

--Experimenting with NLP
------------
!pip install -q transformers
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification
import tensorflow as tf

Paraphrase detection
This nifty pre-trained model has been trained to classify whether two sentences are paraphrases of each other. We start off by loading the pre-trained model. This model has been fine-tuned on this task, meaning that after the initial model was trained to do it's original (more general task), it was then trained with a data set comprising examples of paraphrased sentences. This is a great example of transfer learning.

# Import tokenizer (thing that turns words to number for the model) and the model
tokenizer = AutoTokenizer.from_pretrained("bert-base-cased-finetuned-mrpc")
model = TFAutoModelForSequenceClassification.from_pretrained("bert-base-cased-finetuned-mrpc")
# Setup the two classes for the model
classes = ["not a paraphrase", "a paraphrase"]

Giving model some examples:
sequence_1 = "Rick and Morty is my favourite show on Netflix"
sequence_2 = "I love building machine learning models to understand language"
sequence_3 = "Natural Language Processing is one of my favourite areas of machine learning"

# Tokenize the sentences, turning them into a numerical representation the model can read
paraphrase = tokenizer(sequence_1, sequence_3, return_tensors="tf")
not_paraphrase = tokenizer(sequence_2, sequence_3, return_tensors="tf")

# Let's get the model's predictions
paraphrase_predictions = tf.nn.softmax(model(paraphrase)[0], axis =1).numpy()[0]
not_paraphrase_predictions = tf.nn.softmax(model(not_paraphrase)[0], axis = 1).numpy()[0]

#let's take a look at how good it is at picking up whether one sentence is a paraphrase of another
## Let's take a look at the results from the 1st and 3rd sentences
print(" === Example one ===")
print("Sentence 1: {} \nSentence 2: {}".format(sequence_1, sequence_3))
print("\nModel prediction:")
for i in range(len(classes)):
  print("Probability it's {}: {}%".format(classes[i], round(paraphrase_predictions[i]*100,2)))

# And now from the the 2nd and 3rd sentences
print("\n === Example Two ===")
print("Sentence 2: {} \nSentence 3: {}".format(sequence_2, sequence_3))
print("\nModel prediction:")
for i in range(len(classes)):
  print("Probability it's {}: {}%".format(classes[i], round(not_paraphrase_predictions[i]*100,2)))

Transformers Q&A
#The way the model works is by finding the most likely start and end token (word) positions based on the question asked. The below code utilises a pre-trained model called BERT for Q&A.

from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering
import tensorflow as tf

# We load up the pretrained tokenizer and model, both trained/fine-tuned on a QA task
tokenizer = AutoTokenizer.from_pretrained("bert-large-uncased-whole-word-masking-finetuned-squad")
qa_model = TFAutoModelForQuestionAnswering.from_pretrained("bert-large-uncased-whole-word-masking-finetuned-squad")

# Add some text and questions
text = r"""Apple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne in April 1976 to develop and sell Wozniak's Apple I personal computer, 
           though Wayne sold his share back within 12 days. It was incorporated as Apple Computer, Inc., in January 1977, and sales of its computers, 
           including the Apple II, grew quickly. Within a few years, Jobs and Wozniak had hired a staff of computer designers and had a production line. 
           Apple went public in 1980 to instant financial success. Over the next few years, Apple shipped new computers featuring innovative graphical 
           user interfaces, such as the original Macintosh in 1984, and Apple's marketing advertisements for its products received widespread critical 
           acclaim. However, the high price of its products and limited application library caused problems, as did power struggles between executives. 
           In 1985, Wozniak departed Apple amicably and remained an honorary employee,[9] while Jobs and others resigned to found NeXT.[10]
          As the market for personal computers expanded and evolved through the 1990s, Apple lost market share to the lower-priced duopoly of Microsoft 
          Windows on Intel PC clones. The board recruited CEO Gil Amelio to what would be a 500-day charge for him to rehabilitate the financially troubled 
          companyâ€”reshaping it with layoffs, executive restructuring, and product focus. In 1997, he led Apple to buy NeXT, solving the desperately 
          failed operating system strategy and bringing Jobs back. Jobs pensively regained leadership status, becoming CEO in 2000. Apple swiftly 
          returned to profitability under the revitalizing Think different campaign, as he rebuilt Apple's status by launching the iMac in 1998, 
          opening the retail chain of Apple Stores in 2001, and acquiring numerous companies to broaden the software portfolio. In January 2007, 
          Jobs renamed the company Apple Inc., reflecting its shifted focus toward consumer electronics, and launched the iPhone to great critical 
          acclaim and financial success. In August 2011, Jobs resigned as CEO due to health complications, and Tim Cook became the new CEO. 
          Two months later, Jobs died, marking the end of an era for the company. 
      """

questions = ["Who founded Apple?",
             "Where did Apple lose market share?"]

How does Model do it??

def answer_question(question, text):
  # Function that simplifies answering a question
  for question in questions:
    # Concatenate the question and the textx
    inputs = tokenizer(question, text, add_special_tokens = True, return_tensors = 'tf')
    # Get the input ids (numbers) and convert to tokens (words)
    input_ids = inputs["input_ids"].numpy()[0]
    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)
    # Run the pretrained model to get the logits (raw scores) for the scores
    output = qa_model(inputs)

    # Get the most likely beginning and end
    answer_start = tf.argmax(output.start_logits, axis = 1).numpy()[0]
    answer_end = (tf.argmax(output.end_logits, axis = 1)+1).numpy()[0]
    # Turn the tokens from the ids of the input string, indexed by the start and end tokens back into a string
    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))

    print("Question {} \nAnswer: {}".format(question, answer))

answer_question(questions, text)
------------------



